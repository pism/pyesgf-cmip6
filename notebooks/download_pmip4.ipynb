{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyesgf.search import SearchConnection\n",
    "from pyesgf.logon import LogonManager\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pylab as plt\n",
    "from joblib import Parallel, delayed\n",
    "import operator\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "from cdo import Cdo\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94146af1",
   "metadata": {},
   "source": [
    "## Log on with OpenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ec828",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogonManager()\n",
    "lm.logoff()\n",
    "lm.is_logged_on()\n",
    "\n",
    "my_id = \"aaschwanden\"\n",
    "\n",
    "OPENID = f\"https://esgf-node.llnl.gov/esgf-idp/openid/{my_id}\"\n",
    "lm.logon_with_openid(openid=OPENID, password=None, bootstrap=True)\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3adb42",
   "metadata": {},
   "source": [
    "## Select Experiments and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"lig127k\", \"midPliocene-eoi400\"]\n",
    "variables = [\"pr\", \"tas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc38eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = SearchConnection('https://esgf-node.llnl.gov/esg-search', distrib=True)\n",
    "ctx = conn.new_context(facets='project,experiment_id')\n",
    "facets='project,experiment_family'\n",
    "ctx = conn.new_context(project='CMIP6',\n",
    "                       activity_id=\"PMIP\",\n",
    "                       realm=\"atmos\",\n",
    "                       table_id=\"Amon\",\n",
    "                       variable_id=variables,\n",
    "                       experiment_id=experiments,\n",
    "                       facets=facets)\n",
    "print('Hits:', ctx.hit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(result):\n",
    "    return list(map(lambda f : {'variable': f.filename.split(\"_\")[0], \n",
    "                                'table_id': f.filename.split(\"_\")[1],\n",
    "                                'source_id': f.filename.split(\"_\")[2],\n",
    "                                'experiment_id': f.filename.split(\"_\")[3],\n",
    "                                'sub_experiment_id': f.filename.split(\"_\")[4],\n",
    "                                'filename': f.filename, \n",
    "                                'url': f.opendap_url, \n",
    "                                'size': f.size, \n",
    "                                'checksum': f.checksum, \n",
    "                                'checksum_type': f.checksum_type},\n",
    "                    result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fedf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 16\n",
    "results = ctx.search()\n",
    "n_files = len(results)\n",
    "\n",
    "joblib_files = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(mapping)(results[i].file_context().search())\n",
    "    for i in tqdm(range(n_files))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83902a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [joblib_files[i][0] for i in range(len(joblib_files)) if len(joblib_files[i]) > 0]\n",
    "all_files = sorted(all_files, key=operator.itemgetter(\"filename\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b28ab4",
   "metadata": {},
   "source": [
    "## Generate a DataFrame with all files. Save to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d66129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_files).drop_duplicates()\n",
    "df.to_csv(\"experiments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd849ee",
   "metadata": {},
   "source": [
    "## Read Experiment Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(row, odir: Union[Path, str] = \"pmip_raw\"):\n",
    "    \"\"\"\n",
    "    Download function\n",
    "    \"\"\"\n",
    "    url = row[\"url\"]\n",
    "    filename = Path(row[\"filename\"])\n",
    "    if not isinstance(odir, Path):\n",
    "        odir = Path(odir)\n",
    "    odir.mkdir(exist_ok=True)\n",
    "    m_filename = odir / filename\n",
    "    try:\n",
    "        ds = xr.open_dataset(url, decode_times=False, engine=\"netcdf4\")\n",
    "        if not Path(m_filename).exists():\n",
    "            ds = xr.open_dataset(url, decode_times=False)\n",
    "            ds[\"experiment_id\"] = ds.attrs[\"experiment_id\"]\n",
    "            if \"pr\" in ds:\n",
    "                ds[\"pr\"] *= 31556925.9747\n",
    "                ds[\"pr\"][\"units\"] = \"kg m-2 yr-1\"\n",
    "            print(f\"Saving {m_filename}\")\n",
    "            ds.to_netcdf(m_filename)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afe9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(df)\n",
    "print(n_files)\n",
    "\n",
    "joblib_files = Parallel(n_jobs=10)(\n",
    "    delayed(download)(row)\n",
    "    for _, row in tqdm(df.iterrows())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdo = Cdo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e2d13-30ea-49b2-b6dc-332e475f26db",
   "metadata": {},
   "source": [
    "## Merge time and remap to common grid to allow computing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da398161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files(files):\n",
    "    if f.exists():\n",
    "        return f.as_posix()\n",
    "\n",
    "n_jobs = 8\n",
    "idir: Union[Path, str] = Path(\"pmip_raw\")\n",
    "odir: Union[Path, str] = Path(\"pmip_processed\")\n",
    "odir.mkdir(exist_ok=True)\n",
    "processed_df = []\n",
    "for (m_var, m_exp, m_source), gcm_df in df.groupby(by=[\"variable\", \"experiment_id\", \"source_id\"]):\n",
    "    ifiles = [idir / Path(f) for f in gcm_df[\"filename\"]]\n",
    "    ofile = odir / Path(f\"{m_var}_Amon_{m_source}_{m_exp}.nc\")\n",
    "    try:\n",
    "        cdo.remapycon(\"r360x180 -timmean -mergetime\", input=[check_file(f) for f in ifiles], output=ofile.as_posix(),  options =f\"-O -f nc -z zip_3 -P {n_jobs}\")\n",
    "        processed_df.append(pd.DataFrame.from_dict({\"variable_id\": [m_var], \"experiment_id\": [m_exp], \"source_id\": [m_source], \"filename\": ofile}))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a136ecc-a13c-4eb7-9bf9-0c2017cd2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "proccessed_df = pd.concat(processed_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4d590-1f1f-4ac7-b146-8e7a570b5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    ds[\"experiment_id\"] = ds.attrs[\"experiment_id\"]\n",
    "    source_id = ds.attrs[\"source_id\"]\n",
    "    ds = ds.assign_coords({\"source_id\": source_id}).drop_vars(\"height\", errors=\"ignore\")\n",
    "    return ds.sel(lat=slice(60, 85), lon=slice(285, 350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f7b6c-c943-4996-b413-3c51c9f91a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection  = proccessed_df.groupby(by=[\"variable_id\", \"experiment_id\"])[\"source_id\"].unique()\n",
    "intersection_gcms = reduce(lambda  left,right: list(set(left).intersection(set(right))), intersection)\n",
    "intersection_df = proccessed_df[proccessed_df[\"source_id\"].isin(intersection_gcms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faba5a8-b98b-496d-a261-32e81a8d3715",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 5\n",
    "lw = 0.65\n",
    "aspect_ratio = 0.35\n",
    "markersize = 2\n",
    "\n",
    "params = {\n",
    "    \"backend\": \"ps\",\n",
    "    \"axes.linewidth\": 0.25,\n",
    "    \"lines.linewidth\": lw,\n",
    "    \"axes.labelsize\": fontsize,\n",
    "    \"font.size\": fontsize,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": fontsize,\n",
    "    \"xtick.major.size\": 2.5,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"ytick.labelsize\": fontsize,\n",
    "    \"ytick.major.size\": 2.5,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"legend.fontsize\": fontsize,\n",
    "    \"lines.markersize\": markersize,\n",
    "    \"font.size\": fontsize,\n",
    "    \"hatch.linewidth\": 0.25,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98cb75-157c-46b9-a216-a533e11d2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm_sel = [\"CESM2\", \"EC-Earth3-LR\", \"IPSL-CM6A-LR\", \"NorESM1-F\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7418f75-87f2-4af6-8636-5323bd0a089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for (m_var, m_exp), m_df in intersection_df.groupby(by=[\"variable_id\", \"experiment_id\"]):\n",
    "    p = m_df[\"filename\"]\n",
    "    ds = xr.open_mfdataset(p, parallel=True, concat_dim=\"source_id\", combine=\"nested\",\n",
    "                           data_vars='minimal', coords='minimal', compat='override', preprocess=preprocess, decode_times=False)\n",
    "    f = ds.sel(source_id=gcm_sel)[m_var].mean(dim=\"time\").plot(figsize=(6.2, 2.4),\n",
    "                                        col=\"source_id\", \n",
    "                                        col_wrap=len(gcm_sel), \n",
    "                                        transform=ccrs.PlateCarree(), \n",
    "                                        cbar_kwargs={\"location\": \"right\", \"orientation\": \"vertical\", \n",
    "                                                     \"fraction\": 0.085, \"shrink\": 0.6, \"label\": ds[m_var].units},\n",
    "                                        subplot_kws={\"projection\": crs})\n",
    "    mean = ds.sel(source_id=gcm_sel)[m_var].mean(dim=[\"time\", \"lat\", \"lon\"]).to_dataframe()\n",
    "    variance = ds[m_var].std(dim=[\"time\", \"source_id\"])\n",
    "    [f.axs.ravel()[source[0]].text(0.5, 0.1, f\"\"\"mean={np.round(source[1][-1].to_numpy()[0])}\"\"\", color=\"w\", horizontalalignment='center',\n",
    "     verticalalignment='center', transform=f.axs.ravel()[source[0]].transAxes) for source in enumerate(mean.iterrows())]\n",
    "    for f_ax in f.axs.flat:\n",
    "        f_ax.coastlines(linewidth=0.25, resolution=\"10m\")\n",
    "        f_ax.set_extent([-60, -30, 58, 85])\n",
    "\n",
    "\n",
    "    f.fig.subplots_adjust(wspace=.1, hspace=.1, right=0.9)\n",
    "    f.fig.savefig(f\"{m_var}_{m_exp}.png\", dpi=600)\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    f_var = variance.plot(ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d79b46d-781d-4118-9764-98023e275cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs = ccrs.NorthPolarStereo(central_longitude=-45, true_scale_latitude=70, globe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e342a1-fe0c-46d4-a352-c11bf2f17719",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_ax.coastlines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ba43dc-a421-4095-8bb5-d70f5349ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226db44d-5f3f-481e-8b33-4c39e1190275",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(source_id=[\"CESM2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83a13d-9b83-4ec4-9bfc-04f0203ea99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ced51-7364-4cb0-a4c1-37a8ca6f2afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice(ds[\"source_id\"], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75442931-f468-40b5-b4a5-fe07cd39ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_gcms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be144ca-0f9a-45aa-8257-538af627469a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
