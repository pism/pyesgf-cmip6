{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61de428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyesgf.search import SearchConnection\n",
    "from pyesgf.logon import LogonManager\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pylab as plt\n",
    "from joblib import Parallel, delayed\n",
    "import operator\n",
    "from typing import Union\n",
    "from tqdm.auto import tqdm\n",
    "from cdo import Cdo\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94146af1",
   "metadata": {},
   "source": [
    "## Log on with OpenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ec828",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LogonManager()\n",
    "lm.logoff()\n",
    "lm.is_logged_on()\n",
    "\n",
    "my_id = \"aaschwanden\"\n",
    "\n",
    "OPENID = f\"https://esgf-node.llnl.gov/esgf-idp/openid/{my_id}\"\n",
    "lm.logon_with_openid(openid=OPENID, password=None, bootstrap=True)\n",
    "lm.is_logged_on()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3adb42",
   "metadata": {},
   "source": [
    "## Select Experiments and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"lig127k\", \"midPliocene-eoi400\"]\n",
    "variables = [\"pr\", \"tas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc38eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = SearchConnection('https://esgf-node.llnl.gov/esg-search', distrib=True)\n",
    "ctx = conn.new_context(facets='project,experiment_id')\n",
    "facets='project,experiment_family'\n",
    "ctx = conn.new_context(project='CMIP6',\n",
    "                       activity_id=\"PMIP\",\n",
    "                       realm=\"atmos\",\n",
    "                       table_id=\"Amon\",\n",
    "                       variable_id=variables,\n",
    "                       experiment_id=experiments,\n",
    "                       facets=facets)\n",
    "print('Hits:', ctx.hit_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(result):\n",
    "    return list(map(lambda f : {'variable': f.filename.split(\"_\")[0], \n",
    "                                'table_id': f.filename.split(\"_\")[1],\n",
    "                                'source_id': f.filename.split(\"_\")[2],\n",
    "                                'experiment_id': f.filename.split(\"_\")[3],\n",
    "                                'sub_experiment_id': f.filename.split(\"_\")[4],\n",
    "                                'filename': f.filename, \n",
    "                                'url': f.opendap_url, \n",
    "                                'size': f.size, \n",
    "                                'checksum': f.checksum, \n",
    "                                'checksum_type': f.checksum_type},\n",
    "                    result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fedf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 16\n",
    "results = ctx.search()\n",
    "n_files = len(results)\n",
    "\n",
    "joblib_files = Parallel(n_jobs=n_jobs)(\n",
    "    delayed(mapping)(results[i].file_context().search())\n",
    "    for i in tqdm(range(n_files))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83902a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [joblib_files[i][0] for i in range(len(joblib_files)) if len(joblib_files[i]) > 0]\n",
    "all_files = sorted(all_files, key=operator.itemgetter(\"filename\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b28ab4",
   "metadata": {},
   "source": [
    "## Generate a DataFrame with all files. Save to disk for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d66129",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_files).drop_duplicates()\n",
    "df.to_csv(\"experiments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd849ee",
   "metadata": {},
   "source": [
    "## Read Experiment Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"experiments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e574a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(row, odir: Union[Path, str] = \"pmip_raw\"):\n",
    "    \"\"\"\n",
    "    Download function\n",
    "    \"\"\"\n",
    "    url = row[\"url\"]\n",
    "    filename = Path(row[\"filename\"])\n",
    "    if not isinstance(odir, Path):\n",
    "        odir = Path(odir)\n",
    "    odir.mkdir(exist_ok=True)\n",
    "    m_filename = odir / filename\n",
    "    try:\n",
    "        ds = xr.open_dataset(url, decode_times=False, engine=\"netcdf4\")\n",
    "        if not Path(m_filename).exists():\n",
    "            ds = xr.open_dataset(url, decode_times=False)\n",
    "            ds[\"experiment_id\"] = ds.attrs[\"experiment_id\"]\n",
    "            if \"pr\" in ds:\n",
    "                ds[\"pr\"] *= 31556925.9747\n",
    "                ds[\"pr\"][\"units\"] = \"kg m-2 yr-1\"\n",
    "            print(f\"Saving {m_filename}\")\n",
    "            ds.to_netcdf(m_filename)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7afe9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_files = len(df)\n",
    "print(n_files)\n",
    "\n",
    "joblib_files = Parallel(n_jobs=10)(\n",
    "    delayed(download)(row)\n",
    "    for _, row in tqdm(df.iterrows())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdo = Cdo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e2d13-30ea-49b2-b6dc-332e475f26db",
   "metadata": {},
   "source": [
    "## Merge time and remap to common grid to allow computing stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da398161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_files(files):\n",
    "    if f.exists():\n",
    "        return f.as_posix()\n",
    "\n",
    "n_jobs = 8\n",
    "idir: Union[Path, str] = Path(\"pmip_raw\")\n",
    "odir: Union[Path, str] = Path(\"pmip_processed\")\n",
    "odir.mkdir(exist_ok=True)\n",
    "processed_df = []\n",
    "for (m_var, m_exp, m_source), gcm_df in df.groupby(by=[\"variable\", \"experiment_id\", \"source_id\"]):\n",
    "    ifiles = [idir / Path(f) for f in gcm_df[\"filename\"]]\n",
    "    ofile = odir / Path(f\"{m_var}_Amon_{m_source}_{m_exp}.nc\")\n",
    "    try:\n",
    "        cdo.remapycon(\"r360x180 -timmean -mergetime\", input=[check_file(f) for f in ifiles], output=ofile.as_posix(),  options =f\"-O -f nc -z zip_3 -P {n_jobs}\")\n",
    "        processed_df.append(pd.DataFrame.from_dict({\"variable_id\": [m_var], \"experiment_id\": [m_exp], \"source_id\": [m_source], \"filename\": ofile}))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a136ecc-a13c-4eb7-9bf9-0c2017cd2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "proccessed_df = pd.concat(processed_df).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4d590-1f1f-4ac7-b146-8e7a570b5724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    ds[\"experiment_id\"] = ds.attrs[\"experiment_id\"]\n",
    "    source_id = ds.attrs[\"source_id\"]\n",
    "    ds = ds.assign_coords({\"source_id\": source_id}).drop(\"height\", errors=\"ignore\")\n",
    "    return ds.sel(lat=slice(60, 85), lon=slice(285, 350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f7b6c-c943-4996-b413-3c51c9f91a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection  = proccessed_df.groupby(by=[\"variable_id\", \"experiment_id\"])[\"source_id\"].unique()\n",
    "intersection_gcms = reduce(lambda  left,right: list(set(left).intersection(set(right))), intersection)\n",
    "intersection_df = proccessed_df[proccessed_df[\"source_id\"].isin(intersection_gcms)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7418f75-87f2-4af6-8636-5323bd0a089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (m_var, m_exp), m_df in intersection_df.groupby(by=[\"variable_id\", \"experiment_id\"]):\n",
    "    p = m_df[\"filename\"]\n",
    "    ds = xr.open_mfdataset(p, parallel=True, concat_dim=\"source_id\", combine=\"nested\",\n",
    "                           data_vars='minimal', coords='minimal', compat='override', preprocess=preprocess, decode_times=False)\n",
    "    f = ds[m_var].mean(dim=\"time\").plot(col=\"source_id\", col_wrap=6)\n",
    "    mean = ds[m_var].mean(dim=[\"time\", \"lat\", \"lon\"]).to_dataframe()\n",
    "    variance = ds[m_var].std(dim=[\"time\", \"source_id\"])\n",
    "    [f.axs.ravel()[source[0]].text(0.1, 0.9, f\"\"\"mean={np.round(source[1][-1].to_numpy()[0])}\"\"\", color=\"w\", horizontalalignment='left',\n",
    "     verticalalignment='center', transform=f.axs.ravel()[source[0]].transAxes) for source in enumerate(mean.iterrows())]\n",
    "    f.fig.savefig(f\"{m_var}_{m_exp}.pdf\")\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    f_var = variance.plot(ax=ax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98cb75-157c-46b9-a216-a533e11d2934",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cle"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
